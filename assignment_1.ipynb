{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Offline phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports, Parameters, and Object Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Setting the expected chessboard pattern size (number of inner corners)\n",
    "pattern_size = (9, 6)\n",
    "square_size = 21.7  # length of each square in mm\n",
    "\n",
    "# Preparing the object points (3D points in the chessboard coordinate system)\n",
    "objp = np.zeros((pattern_size[0]*pattern_size[1], 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape(-1, 2)\n",
    "objp *= square_size\n",
    "\n",
    "# Lists to store all object points and image points\n",
    "object_points_all = []   # 3D points in real-world space\n",
    "image_points_all = []    # 2D points in the image plane\n",
    "\n",
    "# For images that were processed automatically\n",
    "object_points_auto = []\n",
    "image_points_auto = []\n",
    "\n",
    "training_files = glob.glob('training_images/*.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for corner detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOICE 5: Enhance input for automatic detection\n",
    "# Function that enhances the input image to improve automatic chessboard corner detection\n",
    "def preprocess_image(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_eq = cv2.equalizeHist(gray)\n",
    "    gray_blur = cv2.medianBlur(gray_eq, 5)\n",
    "    return gray_blur\n",
    "\n",
    "# Function that allows automatic inner corner detection using OpenCV's chessboard detection functions\n",
    "def detect_corners_automatically(img, pattern_size):\n",
    "    preprocessed = preprocess_image(img)\n",
    "    try:\n",
    "        ret, corners = cv2.findChessboardCornersSB(preprocessed, pattern_size, None)\n",
    "    except Exception:\n",
    "        # Fall back to findChessboardCorners with flags if findChessboardCornersSB is unavailable\n",
    "        flags = cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE\n",
    "        ret, corners = cv2.findChessboardCorners(preprocessed, pattern_size, flags)\n",
    "    return ret, corners\n",
    "\n",
    "# Function that provides an interactive manual annotation interface\n",
    "# Choice 3: Improves the localization of the four corner points by providing zoomed-in feedback, undo, and confirmation\n",
    "def get_manual_corners(img):\n",
    "    clicked_points = []\n",
    "    img_copy = img.copy()\n",
    "    original_img = img.copy()  # used to redraw the image after undo\n",
    "\n",
    "    # Function to update the display of the manual annotation window\n",
    "    def update_display():\n",
    "        nonlocal img_copy\n",
    "        img_copy = original_img.copy()\n",
    "        for pt in clicked_points:\n",
    "            cv2.circle(img_copy, (int(pt[0]), int(pt[1])), 5, (0, 0, 255), -1)\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            cv2.putText(img_copy, f\"{int(pt[0])},{int(pt[1])}\", (int(pt[0]), int(pt[1])),\n",
    "                        font, 0.5, (0, 0, 255), 1)\n",
    "        cv2.imshow(\"Manual Annotation\", img_copy)\n",
    "\n",
    "     # Function that displays a zoomed-in view to help the user click more precisely\n",
    "    def zoom_click_refinement(img, point, zoom_factor=4, window_size=400):\n",
    "        x, y = int(point[0]), int(point[1])\n",
    "        h, w = img.shape[:2]\n",
    "        half = window_size // 2\n",
    "        x1 = max(x - half, 0)\n",
    "        y1 = max(y - half, 0)\n",
    "        x2 = min(x + half, w)\n",
    "        y2 = min(y + half, h)\n",
    "        roi = img[y1:y2, x1:x2]\n",
    "        zoomed = cv2.resize(roi, (roi.shape[1]*zoom_factor, roi.shape[0]*zoom_factor))\n",
    "        win_name = \"Zoomed Refinement\"\n",
    "        cv2.namedWindow(win_name, cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(win_name, zoomed)\n",
    "        refined_point = None\n",
    "\n",
    "        # Callback function for the zoomed-in refinement window\n",
    "        def zoom_callback(event, zx, zy, flags, param):\n",
    "            nonlocal refined_point\n",
    "            if event == cv2.EVENT_LBUTTONDOWN:\n",
    "                rx = zx / zoom_factor\n",
    "                ry = zy / zoom_factor\n",
    "                refined_point = (x1 + rx, y1 + ry)\n",
    "                cv2.destroyWindow(win_name)\n",
    "\n",
    "        cv2.setMouseCallback(win_name, zoom_callback)\n",
    "        while refined_point is None:\n",
    "            key = cv2.waitKey(1)\n",
    "            if key == 27:  # Esc cancels refinement\n",
    "                refined_point = point\n",
    "                cv2.destroyWindow(win_name)\n",
    "                break\n",
    "        return refined_point\n",
    "    \n",
    "    #  Mouse callback function to capture clicks using zoomed-in refinement\n",
    "    def click_event(event, x, y, _flags, _params):\n",
    "        nonlocal clicked_points, img_copy\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            initial_point = (x, y)\n",
    "            refined = zoom_click_refinement(img, initial_point)\n",
    "            clicked_points.append(refined)\n",
    "            update_display()\n",
    "            print(f\"Point selected: {refined}\")\n",
    "\n",
    "    cv2.namedWindow(\"Manual Annotation\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"Manual Annotation\", 1280, 720)\n",
    "    cv2.imshow(\"Manual Annotation\", img_copy)\n",
    "    cv2.setMouseCallback(\"Manual Annotation\", click_event)\n",
    "\n",
    "    print(\"Please click on the 4 outer corners of the chessboard in the following order:\")\n",
    "    print(\"1. Top-Left\")\n",
    "    print(\"2. Top-Right\")\n",
    "    print(\"3. Bottom-Right\")\n",
    "    print(\"4. Bottom-Left\")\n",
    "    print(\"Press 'u' to undo the last click. After 4 clicks, press 'a' to accept or 'u' to undo the final click.\")\n",
    "\n",
    "    while True:\n",
    "        cv2.imshow(\"Manual Annotation\", img_copy)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('u'):\n",
    "            if clicked_points:\n",
    "                clicked_points.pop()\n",
    "                update_display()\n",
    "                print(\"Undid the last click.\")\n",
    "        if len(clicked_points) == 4:\n",
    "            print(\"4 points have been selected. Press 'a' to accept these points, or 'u' to undo the final click.\")\n",
    "            key_confirm = cv2.waitKey(0) & 0xFF\n",
    "            if key_confirm == ord('a'):\n",
    "                break\n",
    "            elif key_confirm == ord('u'):\n",
    "                if clicked_points:\n",
    "                    clicked_points.pop()\n",
    "                    update_display()\n",
    "                    print(\"Undid the last click. Please click again.\")\n",
    "        if key == 27:  # Esc key\n",
    "            print(\"Manual annotation canceled. Not enough points selected.\")\n",
    "            break\n",
    "\n",
    "    cv2.destroyWindow(\"Manual Annotation\")\n",
    "\n",
    "    if len(clicked_points) == 4:\n",
    "        return clicked_points\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "# Function that linearly interpolates all chessboard points from the given outer corners\n",
    "def interpolate_with_homography(corners, grid_size):\n",
    "    num_cols, num_rows = grid_size\n",
    "\n",
    "    # Define the ideal source points in a rectified coordinate system for the inner corners\n",
    "    src_points = np.array([\n",
    "        [0, 0],                     # top-left of inner corners\n",
    "        [num_cols - 1, 0],          # top-right of inner corners\n",
    "        [num_cols - 1, num_rows - 1],  # bottom-right\n",
    "        [0, num_rows - 1]           # bottom-left\n",
    "    ], dtype=np.float32)\n",
    "    dst_points = np.array(corners, dtype=np.float32)\n",
    "    H = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "\n",
    "    # Generate the full grid of points using a list comprehension and convert to a NumPy array\n",
    "    grid_points = np.array([[j, i] for i in range(num_rows) for j in range(num_cols)], dtype=np.float32)\n",
    "    \n",
    "    # Reshape grid_points to (num_rows, num_cols, 2)\n",
    "    grid_points = grid_points.reshape(num_rows, num_cols, 2)\n",
    "            \n",
    "    # Transform the full grid to image points using the homography\n",
    "    full_points = cv2.perspectiveTransform(grid_points.reshape(-1, 1, 2), H)\n",
    "    full_points = full_points.reshape(num_rows, num_cols, 2)\n",
    "    \n",
    "    # Extract only the inner points (exclude the outer rows and columns)\n",
    "    inner_points = full_points[1:-1, 1:-1, :]\n",
    "    return inner_points.reshape(-1, 2)\n",
    "\n",
    "# Function that determines whether the chessboard is placed vertically or horizontally\n",
    "def determine_grid_size(corners, horizontal_grid_size=11, vertical_grid_size=8):\n",
    "    tl = np.array(corners[0], dtype=np.float32)\n",
    "    tr = np.array(corners[1], dtype=np.float32)\n",
    "    bl = np.array(corners[3], dtype=np.float32)\n",
    "    width = np.linalg.norm(tr - tl)\n",
    "    height = np.linalg.norm(bl - tl)\n",
    "    if width >= height:\n",
    "        return (horizontal_grid_size, vertical_grid_size)\n",
    "    else:\n",
    "        return (vertical_grid_size, horizontal_grid_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Each Training Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image: training_images\\WIN_20250211_10_59_26_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images\\WIN_20250211_10_59_58_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images\\WIN_20250211_11_00_39_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images\\WIN_20250211_11_12_01_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images\\WIN_20250211_11_12_06_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images\\WIN_20250211_11_12_12_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images\\WIN_20250211_11_17_19_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images\\WIN_20250212_12_24_40_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images\\WIN_20250212_12_24_45_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images\\WIN_20250212_12_24_50_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images\\WIN_20250212_12_25_06_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images\\WIN_20250212_12_25_11_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images\\WIN_20250212_12_25_16_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images\\WIN_20250212_12_25_21_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images\\WIN_20250212_12_25_27_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images\\WIN_20250212_12_25_32_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images\\WIN_20250212_12_25_37_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images\\WIN_20250212_12_25_42_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images\\WIN_20250213_08_12_52_Pro.jpg\n",
      "Automatic corner detection failed; invoking manual annotation.\n",
      "Please click on the 4 outer corners of the chessboard in the following order:\n",
      "1. Top-Left\n",
      "2. Top-Right\n",
      "3. Bottom-Right\n",
      "4. Bottom-Left\n",
      "Press 'u' to undo the last click. After 4 clicks, press 'a' to accept or 'u' to undo the final click.\n",
      "Point selected: (101.75, 230.25)\n",
      "Point selected: (1663.25, 192.0)\n",
      "Point selected: (1362.75, 570.75)\n",
      "Point selected: (470.0, 603.25)\n",
      "4 points have been selected. Press 'a' to accept these points, or 'u' to undo the final click.\n",
      "\n",
      "Processing image: training_images\\WIN_20250213_08_13_18_Pro.jpg\n",
      "Automatic corner detection failed; invoking manual annotation.\n",
      "Please click on the 4 outer corners of the chessboard in the following order:\n",
      "1. Top-Left\n",
      "2. Top-Right\n",
      "3. Bottom-Right\n",
      "4. Bottom-Left\n",
      "Press 'u' to undo the last click. After 4 clicks, press 'a' to accept or 'u' to undo the final click.\n",
      "Point selected: (905.5, 578.0)\n",
      "Point selected: (1505.25, 250.0)\n",
      "Point selected: (1758.0, 607.25)\n",
      "Point selected: (914.75, 972.75)\n",
      "4 points have been selected. Press 'a' to accept these points, or 'u' to undo the final click.\n",
      "\n",
      "Processing image: training_images\\WIN_20250213_09_07_51_Pro.jpg\n",
      "Automatic corner detection failed; invoking manual annotation.\n",
      "Please click on the 4 outer corners of the chessboard in the following order:\n",
      "1. Top-Left\n",
      "2. Top-Right\n",
      "3. Bottom-Right\n",
      "4. Bottom-Left\n",
      "Press 'u' to undo the last click. After 4 clicks, press 'a' to accept or 'u' to undo the final click.\n",
      "Point selected: (440.0, 155.0)\n",
      "Point selected: (961.75, 92.0)\n",
      "Point selected: (1264.75, 153.75)\n",
      "Point selected: (751.75, 281.25)\n",
      "4 points have been selected. Press 'a' to accept these points, or 'u' to undo the final click.\n",
      "\n",
      "Processing image: training_images\\WIN_20250213_09_07_56_Pro.jpg\n",
      "Automatic corner detection failed; invoking manual annotation.\n",
      "Please click on the 4 outer corners of the chessboard in the following order:\n",
      "1. Top-Left\n",
      "2. Top-Right\n",
      "3. Bottom-Right\n",
      "4. Bottom-Left\n",
      "Press 'u' to undo the last click. After 4 clicks, press 'a' to accept or 'u' to undo the final click.\n",
      "Point selected: (1130.75, 169.75)\n",
      "Point selected: (1789.0, 122.25)\n",
      "Point selected: (1762.75, 239.5)\n",
      "Point selected: (920.0, 276.75)\n",
      "4 points have been selected. Press 'a' to accept these points, or 'u' to undo the final click.\n",
      "\n",
      "Processing image: training_images\\WIN_20250213_09_15_48_Pro.jpg\n",
      "Automatic corner detection succeeded.\n",
      "\n",
      "Processing image: training_images\\WIN_20250213_09_16_23_Pro.jpg\n",
      "Automatic corner detection failed; invoking manual annotation.\n",
      "Please click on the 4 outer corners of the chessboard in the following order:\n",
      "1. Top-Left\n",
      "2. Top-Right\n",
      "3. Bottom-Right\n",
      "4. Bottom-Left\n",
      "Press 'u' to undo the last click. After 4 clicks, press 'a' to accept or 'u' to undo the final click.\n",
      "Point selected: (1028.75, 782.25)\n",
      "Point selected: (1534.0, 774.75)\n",
      "Point selected: (1816.5, 973.75)\n",
      "Point selected: (1190.75, 1024.0)\n",
      "4 points have been selected. Press 'a' to accept these points, or 'u' to undo the final click.\n"
     ]
    }
   ],
   "source": [
    "for idx, fname in enumerate(training_files):\n",
    "    print(f\"\\nProcessing image: {fname}\")\n",
    "    img_train = cv2.imread(fname)\n",
    "    if img_train is None:\n",
    "        print(\"Failed to load image.\")\n",
    "        continue\n",
    "    # Attempt automatic corner detection\n",
    "    ret, corners = detect_corners_automatically(img_train, pattern_size)\n",
    "    \n",
    "    if ret:\n",
    "        print(\"Automatic corner detection succeeded.\")\n",
    "         # Refine corner positions for better accuracy\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "        corners_refined = cv2.cornerSubPix(cv2.cvtColor(img_train, cv2.COLOR_BGR2GRAY), corners, (11, 11), (-1, -1), criteria)\n",
    "\n",
    "        # Add the refined corners and corresponding object points\n",
    "        object_points_all.append(objp)\n",
    "        image_points_all.append(corners_refined)\n",
    "\n",
    "        # Store these in the automatic lists\n",
    "        object_points_auto.append(objp)\n",
    "        image_points_auto.append(corners_refined)\n",
    "\n",
    "        # Draw the detected corners\n",
    "        img_auto = img_train.copy()\n",
    "        cv2.drawChessboardCorners(img_auto, pattern_size, corners_refined, ret)\n",
    "        cv2.namedWindow(\"Automatic Corners\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(\"Automatic Corners\", img_auto)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"Automatic corner detection failed; invoking manual annotation.\")\n",
    "        manual_corners = get_manual_corners(img_train)\n",
    "        if manual_corners is not None:\n",
    "            grid_size_manual = determine_grid_size(manual_corners, horizontal_grid_size=11, vertical_grid_size=8)\n",
    "            corners_manual_full = interpolate_with_homography(manual_corners, grid_size_manual)\n",
    "\n",
    "            # Add the refined corners and corresponding object points\n",
    "            object_points_all.append(objp)\n",
    "            image_points_all.append(corners_manual_full)\n",
    "\n",
    "            # Draw the detected corners\n",
    "            img_with_points = img_train.copy()\n",
    "            for pt in corners_manual_full:\n",
    "                x, y = int(pt[0]), int(pt[1])\n",
    "                cv2.circle(img_with_points, (x, y), 3, (255, 0, 0), -1)\n",
    "            cv2.namedWindow(\"Interpolated Points\", cv2.WINDOW_NORMAL)\n",
    "            cv2.resizeWindow(\"Interpolated Points\", 1280, 720)\n",
    "            cv2.imshow(\"Interpolated Points\", img_with_points)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyWindow(\"Interpolated Points\")\n",
    "        else:\n",
    "            print(\"Skipping image since manual annotation is not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the final test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Image - Detection flag (ret): True\n",
      "Automatic corner detection succeeded on the final test image.\n"
     ]
    }
   ],
   "source": [
    "# Load the final test image\n",
    "final_test_file = \"final_test.jpg\"\n",
    "img_final = cv2.imread(final_test_file)\n",
    "if img_final is None:\n",
    "    print(\"Error: Could not load final test image.\")\n",
    "else:\n",
    "    # Convert the image to grayscale\n",
    "    gray_final = cv2.cvtColor(img_final, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Attempt automatic corner detection using the enhanced function\n",
    "    ret, corners_final = detect_corners_automatically(img_final, pattern_size)\n",
    "    \n",
    "    print(\"Final Test Image - Detection flag (ret):\", ret)\n",
    "    \n",
    "    if ret and corners_final is not None and len(corners_final) > 0:\n",
    "        print(\"Automatic corner detection succeeded on the final test image.\")\n",
    "        # Refine the detected corners for better accuracy using the correctly obtained variable\n",
    "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "        corners_final_refined = cv2.cornerSubPix(gray_final, corners_final, (11, 11), (-1, -1), criteria)\n",
    "\n",
    "        # Add the refined corners and corresponding object points (if needed for calibration)\n",
    "        object_points_all.append(objp)\n",
    "        image_points_all.append(corners_final_refined)\n",
    "        object_points_auto.append(objp)\n",
    "        image_points_auto.append(corners_final_refined)\n",
    "        \n",
    "        # Draw the detected (refined) corners on a copy of the final image\n",
    "        img_final_drawn = img_final.copy()\n",
    "        cv2.drawChessboardCorners(img_final_drawn, pattern_size, corners_final_refined, ret)\n",
    "        \n",
    "        # Display the final test image with detected corners\n",
    "        cv2.namedWindow(\"Final Test Automatic Detection\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(\"Final Test Automatic Detection\", img_final_drawn)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"Automatic corner detection failed on the final test image. Please check the image conditions.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camera Calibration Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choice 4: Function that computes the reprojection error for each image,\n",
    "# providing a quantitative measure (confidence) of how well the camera parameters\n",
    "# have been estimated\n",
    "def compute_reprojection_errors(object_points, image_points, rvecs, tvecs, cameraMatrix, distCoeffs):\n",
    "    total_error = 0\n",
    "    total_points = 0\n",
    "    errors = []\n",
    "    for i in range(len(object_points)):\n",
    "        # Project the 3D object points into the image plane\n",
    "        imgpoints2, _ = cv2.projectPoints(object_points[i], rvecs[i], tvecs[i], cameraMatrix, distCoeffs)\n",
    "        # Ensure that the detected image points are in the same shape and type as imgpoints2\n",
    "        imgpoints_detected = np.array(image_points[i], dtype=np.float32).reshape(-1, 1, 2)\n",
    "        # Compute the L2 norm (reprojection error) for this image\n",
    "        error = cv2.norm(imgpoints_detected, imgpoints2, cv2.NORM_L2) / len(imgpoints2)\n",
    "        errors.append(error)\n",
    "        total_error += error * len(imgpoints2)\n",
    "        total_points += len(imgpoints2)\n",
    "    mean_error = total_error / total_points\n",
    "    std_dev = np.std(errors)\n",
    "    return mean_error, std_dev, errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image size (width x height): (1920, 1080)\n",
      "\n",
      "Run 1 Calibration Results (All Images):\n",
      "Camera Matrix:\n",
      " [[1.33933599e+03 0.00000000e+00 9.74589683e+02]\n",
      " [0.00000000e+00 1.33945326e+03 5.33368459e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "Distortion Coefficients:\n",
      " [[ 0.02261817 -0.00403822  0.00264624 -0.00613085 -0.31281871]]\n",
      "Mean Reprojection Error: 0.116 pixels\n",
      "Standard Deviation: 0.111\n",
      "\n",
      "Run 2 Calibration Results (10 Automatic Images):\n",
      "Camera Matrix:\n",
      " [[1.31618355e+03 0.00000000e+00 9.89617723e+02]\n",
      " [0.00000000e+00 1.31722910e+03 5.52073960e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "Distortion Coefficients:\n",
      " [[-9.34707985e-02  1.04046248e+00  7.20873138e-03  1.44415191e-03\n",
      "  -2.22529826e+00]]\n",
      "Mean Reprojection Error: 0.079 pixels\n",
      "Standard Deviation: 0.026\n",
      "\n",
      "Run 3 Calibration Results (5 Automatic Images):\n",
      "Camera Matrix:\n",
      " [[1.39304935e+03 0.00000000e+00 1.00025686e+03]\n",
      " [0.00000000e+00 1.39116147e+03 5.49802805e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "Distortion Coefficients:\n",
      " [[-2.64372012e-01  3.50280095e+00  1.54706479e-02  5.56904969e-03\n",
      "  -9.01577977e+00]]\n",
      "Mean Reprojection Error: 0.085 pixels\n",
      "Standard Deviation: 0.024\n"
     ]
    }
   ],
   "source": [
    "# Determine image size\n",
    "img_example = cv2.imread(training_files[0])\n",
    "img_size = (img_example.shape[1], img_example.shape[0])\n",
    "print(\"\\nImage size (width x height):\", img_size)\n",
    "\n",
    "# Run 1: Use all training images\n",
    "ret1, cameraMatrix1, distCoeffs1, rvecs1, tvecs1 = cv2.calibrateCamera(\n",
    "    object_points_all, image_points_all, img_size, None, None)\n",
    "print(\"\\nRun 1 Calibration Results (All Images):\")\n",
    "print(\"Camera Matrix:\\n\", cameraMatrix1)\n",
    "print(\"Distortion Coefficients:\\n\", distCoeffs1)\n",
    "\n",
    "mean_error1, std_error1, errors1 = compute_reprojection_errors(object_points_all, image_points_all, rvecs1, tvecs1, cameraMatrix1, distCoeffs1)\n",
    "print(\"Mean Reprojection Error: {:.3f} pixels\".format(mean_error1))\n",
    "print(\"Standard Deviation: {:.3f}\".format(std_error1))\n",
    "\n",
    "# Run 2: Use only 10 images with automatic corner detections\n",
    "if len(object_points_auto) >= 10:\n",
    "    objpoints_run2 = object_points_auto[:10]\n",
    "    imgpoints_run2 = image_points_auto[:10]\n",
    "else:\n",
    "    print(\"Not enough automatic images for Run 2; using available automatic images.\")\n",
    "    objpoints_run2 = object_points_auto\n",
    "    imgpoints_run2 = image_points_auto\n",
    "\n",
    "ret2, cameraMatrix2, distCoeffs2, rvecs2, tvecs2 = cv2.calibrateCamera(\n",
    "    objpoints_run2, imgpoints_run2, img_size, None, None)\n",
    "print(\"\\nRun 2 Calibration Results (10 Automatic Images):\")\n",
    "print(\"Camera Matrix:\\n\", cameraMatrix2)\n",
    "print(\"Distortion Coefficients:\\n\", distCoeffs2)\n",
    "\n",
    "mean_error2, std_error2, errors2 = compute_reprojection_errors(objpoints_run2, imgpoints_run2, rvecs2, tvecs2, cameraMatrix2, distCoeffs2)\n",
    "print(\"Mean Reprojection Error: {:.3f} pixels\".format(mean_error2))\n",
    "print(\"Standard Deviation: {:.3f}\".format(std_error2))\n",
    "\n",
    "# Run 3: Use only 5 images from the automatic ones\n",
    "if len(objpoints_run2) >= 5:\n",
    "    objpoints_run3 = objpoints_run2[:5]\n",
    "    imgpoints_run3 = imgpoints_run2[:5]\n",
    "else:\n",
    "    print(\"Not enough images for Run 3; using available images from Run 2.\")\n",
    "    objpoints_run3 = objpoints_run2\n",
    "    imgpoints_run3 = imgpoints_run2\n",
    "\n",
    "ret3, cameraMatrix3, distCoeffs3, rvecs3, tvecs3 = cv2.calibrateCamera(\n",
    "    objpoints_run3, imgpoints_run3, img_size, None, None)\n",
    "print(\"\\nRun 3 Calibration Results (5 Automatic Images):\")\n",
    "print(\"Camera Matrix:\\n\", cameraMatrix3)\n",
    "print(\"Distortion Coefficients:\\n\", distCoeffs3)\n",
    "\n",
    "mean_error3, std_error3, errors3 = compute_reprojection_errors(objpoints_run3, imgpoints_run3, rvecs3, tvecs3, cameraMatrix3, distCoeffs3)\n",
    "print(\"Mean Reprojection Error: {:.3f} pixels\".format(mean_error3))\n",
    "print(\"Standard Deviation: {:.3f}\".format(std_error3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate color based on position and orientation\n",
    "def calculate_hsv_color(rvec, tvec, top_plane_normal=[0, 0, 1]):\n",
    "    # Calculate distance to camera (for intensity/value) and convert tvec (in mm) to meters\n",
    "    distance = np.linalg.norm(tvec) / 1000.0\n",
    "    value = max(0, 255 * (1 - distance/4))  # Linear scaling 0-4m to 255-0\n",
    "    \n",
    "    # Calculate angle between camera and top plane normal (for saturation)\n",
    "    R, _ = cv2.Rodrigues(rvec)\n",
    "    transformed_normal = R.dot(top_plane_normal)\n",
    "    angle = np.arccos(transformed_normal[2]) * 180/np.pi\n",
    "    saturation = max(0, 255 * (1 - angle/45))\n",
    "    \n",
    "    # Calculate hue based on relative position\n",
    "    # Using horizontal position (x-coordinate) for hue\n",
    "    hue = (np.arctan2(tvec[0][0], tvec[2][0]) + np.pi) * 180/np.pi\n",
    "    \n",
    "    return np.uint8([[[hue, saturation, value]]])\n",
    "\n",
    "# Function to draw cube and axes\n",
    "def draw_cube_and_axes(img, rvec, tvec, camera_matrix, dist_coeffs, square_size):\n",
    "    # Define 3D points for coordinate axes (length = 3 squares)\n",
    "    axis_length = 3 * square_size\n",
    "    axes = np.float32([[0,0,0], [axis_length,0,0], [0,axis_length,0], [0,0,-axis_length]])\n",
    "    \n",
    "    # Define cube points (2x2x2 squares)\n",
    "    cube_size = 2 * square_size\n",
    "    cube_points = np.float32([\n",
    "        [0,0,0], [cube_size,0,0], [cube_size,cube_size,0], [0,cube_size,0],\n",
    "        [0,0,-cube_size], [cube_size,0,-cube_size], \n",
    "        [cube_size,cube_size,-cube_size], [0,cube_size,-cube_size]\n",
    "    ])\n",
    "    \n",
    "    # Project points\n",
    "    imgpts_axes, _ = cv2.projectPoints(axes, rvec, tvec, camera_matrix, dist_coeffs)\n",
    "    imgpts_cube, _ = cv2.projectPoints(cube_points, rvec, tvec, camera_matrix, dist_coeffs)\n",
    "    \n",
    "    # Draw axes\n",
    "    origin = tuple(map(int, imgpts_axes[0].ravel()))\n",
    "    img = cv2.line(img, origin, tuple(map(int, imgpts_axes[1].ravel())), (255,0,0), 3)  # X axis\n",
    "    img = cv2.line(img, origin, tuple(map(int, imgpts_axes[2].ravel())), (0,255,0), 3)  # Y axis\n",
    "    img = cv2.line(img, origin, tuple(map(int, imgpts_axes[3].ravel())), (0,0,255), 3)  # Z axis\n",
    "    \n",
    "    # Draw cube\n",
    "    imgpts_cube = np.int32(imgpts_cube).reshape(-1,2)\n",
    "    \n",
    "    # Draw bottom face\n",
    "    img = cv2.drawContours(img, [imgpts_cube[:4]], -1, (0,255,0), 3)\n",
    "    \n",
    "    # Draw top face\n",
    "    img = cv2.drawContours(img, [imgpts_cube[4:]], -1, (0,255,0), 3)\n",
    "    \n",
    "    # Draw vertical edges\n",
    "    for i in range(4):\n",
    "        img = cv2.line(img, tuple(imgpts_cube[i]), tuple(imgpts_cube[i+4]), (0,255,0), 3)\n",
    "    \n",
    "    # Get color for top polygon based on position and orientation\n",
    "    hsv_color = calculate_hsv_color(rvec, tvec)\n",
    "    bgr_color = cv2.cvtColor(hsv_color, cv2.COLOR_HSV2BGR).squeeze()\n",
    "    \n",
    "    # Draw filled top polygon\n",
    "    top_face = imgpts_cube[4:].reshape((-1,1,2))\n",
    "    cv2.fillConvexPoly(img, top_face, bgr_color.tolist())\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "# Process test image with all three calibration results\n",
    "test_img = cv2.imread(\"final_test.jpg\")\n",
    "\n",
    "# Attempt automatic corner detection using the enhanced function\n",
    "ret, corners = detect_corners_automatically(test_img, pattern_size)\n",
    "\n",
    "if ret:\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "    corners = cv2.cornerSubPix(cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY), corners, (11, 11), (-1, -1), criteria)\n",
    "    \n",
    "    # Process with each calibration result\n",
    "    for run, (camera_matrix, dist_coeffs) in enumerate([\n",
    "        (cameraMatrix1, distCoeffs1),\n",
    "        (cameraMatrix2, distCoeffs2),\n",
    "        (cameraMatrix3, distCoeffs3)\n",
    "    ], 1):\n",
    "        # Find pose\n",
    "        _, rvec, tvec = cv2.solvePnP(objp, corners, camera_matrix, dist_coeffs)\n",
    "        \n",
    "        # Draw results\n",
    "        img_result = test_img.copy()\n",
    "        img_result = draw_cube_and_axes(img_result, rvec, tvec, camera_matrix, dist_coeffs, square_size)\n",
    "        \n",
    "        # Display result\n",
    "        cv2.namedWindow(f\"Run {run} Result\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(f\"Run {run} Result\", img_result)\n",
    "        cv2.waitKey(0)\n",
    "        \n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"Could not detect corners in test image automatically\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
